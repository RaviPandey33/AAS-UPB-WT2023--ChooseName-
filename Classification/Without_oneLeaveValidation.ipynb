{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For not-normalized features :\n",
      "\n",
      "Mean Accuracy (XGBoost): 0.85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        BSqi       1.00      0.50      0.67         2\n",
      "        BSrr       0.50      1.00      0.67         1\n",
      "     CMA-CSA       1.00      1.00      1.00         2\n",
      "        HCMA       1.00      1.00      1.00         2\n",
      "       HMLSL       1.00      1.00      1.00         4\n",
      "    IPOP400D       1.00      1.00      1.00         2\n",
      "         MCS       0.00      0.00      0.00         0\n",
      "       OQNLP       0.50      1.00      0.67         1\n",
      "   SMAC-BBOB       1.00      0.50      0.67         2\n",
      "     fmincon       1.00      1.00      1.00         2\n",
      "     fminunc       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.85        20\n",
      "   macro avg       0.82      0.77      0.76        20\n",
      "weighted avg       0.95      0.85      0.87        20\n",
      "\n",
      "Mean Recall (XGBoost): 0.85\n",
      "Mean F1 Score (XGBoost): 0.8666666666666666\n",
      "Mean Confusion Matrix (XGBoost):\n",
      "[[1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 4. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/flyboyravi/opt/miniconda3/envs/SeminarAAS/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/flyboyravi/opt/miniconda3/envs/SeminarAAS/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/flyboyravi/opt/miniconda3/envs/SeminarAAS/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "ELA_Data = pd.read_csv('median_features.csv')\n",
    "ERT_Data = pd.read_csv('rel_ERT.csv')\n",
    "\n",
    "\n",
    "class ClassifierTrainer_notNormalized:\n",
    "    def __init__(self, ELA_Data, ERT_Data, target_columns):\n",
    "        \n",
    "        \n",
    "        # print(type(ELA_Data), type(ERT_Data))\n",
    "        \n",
    "        \n",
    "        self.data = pd.merge(ELA_Data, ERT_Data, on=['dim','fid'], how='left')\n",
    "        \n",
    "        self.target_columns = target_columns\n",
    "        self.data['min_value_column'] = self.data[target_columns].idxmin(axis=1)\n",
    "        \n",
    "\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.data['min_value_column'] = self.label_encoder.fit_transform(self.data['min_value_column'])\n",
    "        \n",
    "        self.X = self.data.drop('min_value_column', axis=1)\n",
    "        # self.Y = self.data('min_value_column')\n",
    "        \n",
    "        self.loo = LeaveOneOut()\n",
    "        self.rf_classifier = None\n",
    "        self.svm_classifier = None\n",
    "        self.xgb_classifier = None\n",
    "\n",
    "    def _train_classifier(self, classifier, name, Y_encoded):\n",
    "          \n",
    "      \n",
    "        accuracies = []\n",
    "        recall_scores = []\n",
    "        f1_scores = []\n",
    "        confusion_matrices = []\n",
    "        \n",
    "\n",
    "\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(self.X, self.data[\"min_value_column\"], test_size=0.2, random_state=42)\n",
    "        \n",
    "        classifier.fit(X_train, Y_train)\n",
    "\n",
    "        Y_pred = classifier.predict(X_test)\n",
    "\n",
    "        accuracies.append(accuracy_score(Y_test, Y_pred))\n",
    "        recall_scores.append(recall_score(Y_test, Y_pred, average='weighted', zero_division=0))\n",
    "        f1_scores.append(f1_score(Y_test, Y_pred, average='weighted'))\n",
    "        confusion_matrices.append(confusion_matrix(Y_test, Y_pred, labels=np.unique(Y_encoded)))\n",
    "        \n",
    "    \n",
    "\n",
    "        mean_accuracy = np.mean(accuracies)\n",
    "        mean_recall = np.mean(recall_scores)\n",
    "        mean_f1_score = np.mean(f1_scores)\n",
    "        mean_confusion_matrix = np.mean(confusion_matrices, axis=0)\n",
    "\n",
    "        print(\"For not-normalized features :\")\n",
    "        print()\n",
    "        print(f\"Mean Accuracy ({name}): {mean_accuracy}\")\n",
    "        \n",
    "\n",
    "        original_labels_Y_pred = self.label_encoder.inverse_transform(Y_pred)\n",
    "        original_labels_Y_test = self.label_encoder.inverse_transform(Y_test)\n",
    "        \n",
    "        print(classification_report(original_labels_Y_test, original_labels_Y_pred))\n",
    "        \n",
    "        print(f\"Mean Recall ({name}): {mean_recall}\")\n",
    "        print(f\"Mean F1 Score ({name}): {mean_f1_score}\")\n",
    "        print(f\"Mean Confusion Matrix ({name}):\")\n",
    "        print(mean_confusion_matrix)\n",
    "\n",
    "    def train_random_forest(self):\n",
    "        self.rf_classifier = RandomForestClassifier(n_estimators=500, random_state=42)\n",
    "        self._train_classifier(self.rf_classifier, \"Random Forest\", self.data['min_value_column'])\n",
    "\n",
    "    def train_svm(self):\n",
    "        self.svm_classifier = SVC(kernel='linear')\n",
    "        self._train_classifier(self.svm_classifier, \"SVM\", self.data['min_value_column'])\n",
    "\n",
    "    def train_xgboost(self):\n",
    "        self.xgb_classifier = XGBClassifier()\n",
    "        \n",
    "        \n",
    "        # Encode the target variable Y to ensure sequential class labels\n",
    "        label_encoder = LabelEncoder()\n",
    "        Y_encoded = label_encoder.fit_transform( self.data['min_value_column'])\n",
    "        \n",
    "        \n",
    "\n",
    "        self._train_classifier(self.xgb_classifier, \"XGBoost\",  self.data['min_value_column'])\n",
    "\n",
    "    def predict(self, classifier, X_new):\n",
    "        if classifier is not None:\n",
    "            return classifier.predict(X_new)\n",
    "        else:\n",
    "            raise ValueError(\"Classifier not trained yet.\")\n",
    "\n",
    "# Create an instance of ClassifierTrainer\n",
    "target_column = [\"BSqi\", \"BSrr\", \"CMA-CSA\", \"fmincon\", \"fminunc\", \"HCMA\",\n",
    "                  \"HMLSL\", \"IPOP400D\", \"MCS\", \"MLSL\", \"OQNLP\", \"SMAC-BBOB\"]\n",
    "\n",
    "\n",
    "trainer = ClassifierTrainer_notNormalized(ELA_Data, ERT_Data, target_column)\n",
    "\n",
    "# # Train the Random Forest classifier\n",
    "# trainer.train_random_forest()\n",
    "\n",
    "# # Train the SVM classifier\n",
    "# trainer.train_svm()\n",
    "\n",
    "# Train the XGBoost classifier\n",
    "trainer.train_xgboost()\n",
    "\n",
    "# Optionally, you can make predictions using the trained classifiers\n",
    "# For example, assuming you have a new data point X_new and you want to use the Random Forest classifier:\n",
    "# predicted_labels_rf = trainer.predict(trainer.rf_classifier, X_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For normalized features :\n",
      "\n",
      "Mean Accuracy (XGBoost): 0.85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        BSqi       1.00      0.50      0.67         2\n",
      "        BSrr       0.50      1.00      0.67         1\n",
      "     CMA-CSA       1.00      1.00      1.00         2\n",
      "        HCMA       1.00      1.00      1.00         2\n",
      "       HMLSL       1.00      1.00      1.00         4\n",
      "    IPOP400D       1.00      1.00      1.00         2\n",
      "         MCS       0.00      0.00      0.00         0\n",
      "       OQNLP       0.50      1.00      0.67         1\n",
      "   SMAC-BBOB       1.00      0.50      0.67         2\n",
      "     fmincon       1.00      1.00      1.00         2\n",
      "     fminunc       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.85        20\n",
      "   macro avg       0.82      0.77      0.76        20\n",
      "weighted avg       0.95      0.85      0.87        20\n",
      "\n",
      "Mean Recall (XGBoost): 0.85\n",
      "Mean F1 Score (XGBoost): 0.8666666666666666\n",
      "Mean Confusion Matrix (XGBoost):\n",
      "[[1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 4. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/flyboyravi/opt/miniconda3/envs/SeminarAAS/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/flyboyravi/opt/miniconda3/envs/SeminarAAS/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/flyboyravi/opt/miniconda3/envs/SeminarAAS/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "ELA_Data = pd.read_csv('n_median_features.csv')\n",
    "ERT_Data = pd.read_csv('rel_ERT.csv')\n",
    "\n",
    "\n",
    "class ClassifierTrainer_notNormalized:\n",
    "    def __init__(self, ELA_Data, ERT_Data, target_columns):\n",
    "        \n",
    "        \n",
    "        # print(type(ELA_Data), type(ERT_Data))\n",
    "        \n",
    "        \n",
    "        self.data = pd.merge(ELA_Data, ERT_Data, on=['dim','fid'], how='left')\n",
    "        \n",
    "        self.target_columns = target_columns\n",
    "        self.data['min_value_column'] = self.data[target_columns].idxmin(axis=1)\n",
    "        \n",
    "\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.data['min_value_column'] = self.label_encoder.fit_transform(self.data['min_value_column'])\n",
    "        \n",
    "        self.X = self.data.drop('min_value_column', axis=1)\n",
    "        # self.Y = self.data('min_value_column')\n",
    "        \n",
    "        self.loo = LeaveOneOut()\n",
    "        self.rf_classifier = None\n",
    "        self.svm_classifier = None\n",
    "        self.xgb_classifier = None\n",
    "\n",
    "    def _train_classifier(self, classifier, name, Y_encoded):\n",
    "          \n",
    "      \n",
    "        accuracies = []\n",
    "        recall_scores = []\n",
    "        f1_scores = []\n",
    "        confusion_matrices = []\n",
    "        \n",
    "\n",
    "\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(self.X, self.data[\"min_value_column\"], test_size=0.2, random_state=42)\n",
    "        \n",
    "        classifier.fit(X_train, Y_train)\n",
    "\n",
    "        Y_pred = classifier.predict(X_test)\n",
    "\n",
    "        accuracies.append(accuracy_score(Y_test, Y_pred))\n",
    "        recall_scores.append(recall_score(Y_test, Y_pred, average='weighted', zero_division=0))\n",
    "        f1_scores.append(f1_score(Y_test, Y_pred, average='weighted'))\n",
    "        confusion_matrices.append(confusion_matrix(Y_test, Y_pred, labels=np.unique(Y_encoded)))\n",
    "        \n",
    "    \n",
    "\n",
    "        mean_accuracy = np.mean(accuracies)\n",
    "        mean_recall = np.mean(recall_scores)\n",
    "        mean_f1_score = np.mean(f1_scores)\n",
    "        mean_confusion_matrix = np.mean(confusion_matrices, axis=0)\n",
    "\n",
    "        print(\"For normalized features :\")\n",
    "        print()\n",
    "        print(f\"Mean Accuracy ({name}): {mean_accuracy}\")\n",
    "        \n",
    "\n",
    "        original_labels_Y_pred = self.label_encoder.inverse_transform(Y_pred)\n",
    "        original_labels_Y_test = self.label_encoder.inverse_transform(Y_test)\n",
    "        \n",
    "        print(classification_report(original_labels_Y_test, original_labels_Y_pred))\n",
    "        \n",
    "        print(f\"Mean Recall ({name}): {mean_recall}\")\n",
    "        print(f\"Mean F1 Score ({name}): {mean_f1_score}\")\n",
    "        print(f\"Mean Confusion Matrix ({name}):\")\n",
    "        print(mean_confusion_matrix)\n",
    "\n",
    "    def train_random_forest(self):\n",
    "        self.rf_classifier = RandomForestClassifier(n_estimators=500, random_state=42)\n",
    "        self._train_classifier(self.rf_classifier, \"Random Forest\", self.data['min_value_column'])\n",
    "\n",
    "    def train_svm(self):\n",
    "        self.svm_classifier = SVC(kernel='linear')\n",
    "        self._train_classifier(self.svm_classifier, \"SVM\", self.data['min_value_column'])\n",
    "\n",
    "    def train_xgboost(self):\n",
    "        self.xgb_classifier = XGBClassifier()\n",
    "        \n",
    "        \n",
    "        # Encode the target variable Y to ensure sequential class labels\n",
    "        label_encoder = LabelEncoder()\n",
    "        Y_encoded = label_encoder.fit_transform( self.data['min_value_column'])\n",
    "        \n",
    "        \n",
    "\n",
    "        self._train_classifier(self.xgb_classifier, \"XGBoost\",  self.data['min_value_column'])\n",
    "\n",
    "    def predict(self, classifier, X_new):\n",
    "        if classifier is not None:\n",
    "            return classifier.predict(X_new)\n",
    "        else:\n",
    "            raise ValueError(\"Classifier not trained yet.\")\n",
    "\n",
    "# Create an instance of ClassifierTrainer\n",
    "target_column = [\"BSqi\", \"BSrr\", \"CMA-CSA\", \"fmincon\", \"fminunc\", \"HCMA\",\n",
    "                  \"HMLSL\", \"IPOP400D\", \"MCS\", \"MLSL\", \"OQNLP\", \"SMAC-BBOB\"]\n",
    "\n",
    "\n",
    "trainer = ClassifierTrainer_notNormalized(ELA_Data, ERT_Data, target_column)\n",
    "\n",
    "# # Train the Random Forest classifier\n",
    "# trainer.train_random_forest()\n",
    "\n",
    "# # Train the SVM classifier\n",
    "# trainer.train_svm()\n",
    "\n",
    "# Train the XGBoost classifier\n",
    "trainer.train_xgboost()\n",
    "\n",
    "# Optionally, you can make predictions using the trained classifiers\n",
    "# For example, assuming you have a new data point X_new and you want to use the Random Forest classifier:\n",
    "# predicted_labels_rf = trainer.predict(trainer.rf_classifier, X_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SeminarAAS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
