{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For normalized features :\n",
      "\n",
      "Mean Accuracy (XGBoost): 0.9270833333333334\n",
      "Mean Recall (XGBoost): 0.9270833333333334\n",
      "Mean F1 Score (XGBoost): 0.9270833333333334\n",
      "\n",
      "\n",
      "Mean Confusion Matrix (XGBoost):\n",
      "[[0.05208333 0.01041667 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.01041667 0.05208333 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.07291667 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.14583333 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.01041667 0.09375    0.\n",
      "  0.         0.         0.         0.         0.01041667 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.07291667\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.03125    0.         0.         0.01041667 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.03125    0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.0625     0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.01041667 0.         0.         0.04166667 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.21875    0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.01041667 0.         0.         0.05208333]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "ELA_Data = pd.read_csv('n_median_features.csv')\n",
    "ERT_Data = pd.read_csv('rel_ERT.csv')\n",
    "\n",
    "\n",
    "class ClassifierTrainer_Normalized:\n",
    "    def __init__(self, ELA_Data, ERT_Data, target_columns):\n",
    "        \n",
    "        \n",
    "        # print(type(ELA_Data), type(ERT_Data))\n",
    "        \n",
    "        \n",
    "        self.data = pd.merge(ELA_Data, ERT_Data, on=['dim','fid'], how='left')\n",
    "        \n",
    "        self.target_columns = target_columns\n",
    "        self.data['min_value_column'] = self.data[target_columns].idxmin(axis=1)\n",
    "        \n",
    "\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.data['min_value_column'] = self.label_encoder.fit_transform(self.data['min_value_column'])\n",
    "        \n",
    "        self.X = self.data.drop('min_value_column', axis=1)\n",
    "        # self.Y = self.data('min_value_column')\n",
    "        \n",
    "        self.loo = LeaveOneOut()\n",
    "        self.rf_classifier = None\n",
    "        self.svm_classifier = None\n",
    "        self.xgb_classifier = None\n",
    "\n",
    "    def _train_classifier(self, classifier, name, Y_encoded):\n",
    "          \n",
    "      \n",
    "        accuracies = []\n",
    "        recall_scores = []\n",
    "        f1_scores = []\n",
    "        confusion_matrices = []\n",
    "        \n",
    "        # X_train, X_test = self.X[train_index], self.X[test_index]\n",
    "        #     X_train, X_test = self.X.iloc[train_index], self.X.iloc[test_index]\n",
    "            \n",
    "        #     # Y_train, Y_test = Y_encoded[train_index], Y_encoded[test_index]\n",
    "        #     Y_train, Y_test = self.data[\"min_value_column\"].iloc[train_index], self.data[\"min_value_column\"].iloc[test_index]\n",
    "            \n",
    "        #     # print(\"#######################\")\n",
    "        #     # print(type(self.X))\n",
    "        #     # print(\"#######################\")\n",
    "\n",
    "        #     classifier.fit(X_train, Y_train)\n",
    "\n",
    "        #     Y_pred = classifier.predict(X_test)\n",
    "\n",
    "        for train_index, test_index in self.loo.split(self.X):\n",
    "            # X_train, X_test = self.X[train_index], self.X[test_index]\n",
    "            X_train, X_test = self.X.iloc[train_index], self.X.iloc[test_index]\n",
    "            \n",
    "            # Y_train, Y_test = Y_encoded[train_index], Y_encoded[test_index]\n",
    "            Y_train, Y_test = self.data[\"min_value_column\"].iloc[train_index], self.data[\"min_value_column\"].iloc[test_index]\n",
    "            \n",
    "            # print(\"#######################\")\n",
    "            # print(type(self.X))\n",
    "            # print(\"#######################\")\n",
    "\n",
    "            classifier.fit(X_train, Y_train)\n",
    "\n",
    "            Y_pred = classifier.predict(X_test)\n",
    "\n",
    "            accuracies.append(accuracy_score(Y_test, Y_pred))\n",
    "            recall_scores.append(recall_score(Y_test, Y_pred, average='weighted', zero_division=0))\n",
    "            f1_scores.append(f1_score(Y_test, Y_pred, average='weighted'))\n",
    "            confusion_matrices.append(confusion_matrix(Y_test, Y_pred, labels=np.unique(Y_encoded)))\n",
    "\n",
    "        mean_accuracy = np.mean(accuracies)\n",
    "        mean_recall = np.mean(recall_scores)\n",
    "        mean_f1_score = np.mean(f1_scores)\n",
    "        mean_confusion_matrix = np.mean(confusion_matrices, axis=0)\n",
    "\n",
    "\n",
    "        \n",
    "        print(\"For normalized features :\")\n",
    "        print()\n",
    "        print(f\"Mean Accuracy ({name}): {mean_accuracy}\")\n",
    "        \n",
    "\n",
    "        # original_labels_Y_pred = self.label_encoder.inverse_transform(Y_pred)\n",
    "        # original_labels_Y_test = self.label_encoder.inverse_transform(Y_test)\n",
    "        \n",
    "        # print(classification_report(original_labels_Y_test, original_labels_Y_pred))\n",
    "        \n",
    "        \n",
    "        print(f\"Mean Recall ({name}): {mean_recall}\")\n",
    "        print(f\"Mean F1 Score ({name}): {mean_f1_score}\")\n",
    "        \n",
    "        \n",
    "        print()\n",
    "        print()\n",
    "        print(f\"Mean Confusion Matrix ({name}):\")\n",
    "        print(mean_confusion_matrix)\n",
    "\n",
    "    def train_random_forest(self):\n",
    "        self.rf_classifier = RandomForestClassifier(n_estimators=500, random_state=42)\n",
    "        self._train_classifier(self.rf_classifier, \"Random Forest\", self.data['min_value_column'])\n",
    "\n",
    "    def train_svm(self):\n",
    "        self.svm_classifier = SVC(kernel='linear')\n",
    "        self._train_classifier(self.svm_classifier, \"SVM\", self.data['min_value_column'])\n",
    "\n",
    "    def train_xgboost(self):\n",
    "        self.xgb_classifier = XGBClassifier()\n",
    "        \n",
    "        \n",
    "        # Encode the target variable Y to ensure sequential class labels\n",
    "        label_encoder = LabelEncoder()\n",
    "        Y_encoded = label_encoder.fit_transform( self.data['min_value_column'])\n",
    "        \n",
    "        \n",
    "\n",
    "        self._train_classifier(self.xgb_classifier, \"XGBoost\",  self.data['min_value_column'])\n",
    "\n",
    "    def predict(self, classifier, X_new):\n",
    "        if classifier is not None:\n",
    "            return classifier.predict(X_new)\n",
    "        else:\n",
    "            raise ValueError(\"Classifier not trained yet.\")\n",
    "\n",
    "# Create an instance of ClassifierTrainer\n",
    "target_column = [\"BSqi\", \"BSrr\", \"CMA-CSA\", \"fmincon\", \"fminunc\", \"HCMA\",\n",
    "                  \"HMLSL\", \"IPOP400D\", \"MCS\", \"MLSL\", \"OQNLP\", \"SMAC-BBOB\"]\n",
    "\n",
    "\n",
    "trainer = ClassifierTrainer_Normalized(ELA_Data, ERT_Data, target_column)\n",
    "\n",
    "# # Train the Random Forest classifier\n",
    "# trainer.train_random_forest()\n",
    "\n",
    "# # Train the SVM classifier\n",
    "# trainer.train_svm()\n",
    "\n",
    "# Train the XGBoost classifier\n",
    "trainer.train_xgboost()\n",
    "\n",
    "# Optionally, you can make predictions using the trained classifiers\n",
    "# For example, assuming you have a new data point X_new and you want to use the Random Forest classifier:\n",
    "# predicted_labels_rf = trainer.predict(trainer.rf_classifier, X_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SeminarAAS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
